{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d23807be-efde-4096-81e3-2a9acdcba8ac",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 16px;\">\n",
    "   \n",
    "# Data Science Salary - Data Cleaning </div>\n",
    "\n",
    "This notebook focuses on cleaning and preparing the Data Science salary dataset for analysis. I will ensure data quality, handle missing values, identify and address outliers, validate data consistency, and prepare a clean dataset for comprehensive salary analysis.\n",
    "\n",
    "**Data source**: [Kaggle - Data Science Job Salaries](https://www.kaggle.com/datasets/adilshamim8/salaries-for-data-science-jobs)\n",
    "\n",
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 16px;\">\n",
    "   \n",
    "## Dataset Description</div>\n",
    "\n",
    "The dataset contains salary information for data science professionals with the following structure:\n",
    "\n",
    "| **Column Name** | **Description** |\n",
    "|-------------|-------------|\n",
    "| `work_year` | Year of employment (2020-2025) |\n",
    "| `experience_level` | Experience level (EN/MI/SE/EX) |\n",
    "| `employment_type` | Type of employment (FT/PT/CT/FL) |\n",
    "| `job_title` | Specific job title in data science field |\n",
    "| `salary` | Salary in original currency |\n",
    "| `salary_currency` | Currency of salary |\n",
    "| `salary_in_usd` | Salary converted to USD |\n",
    "| `employee_residence` | Country of employee residence |\n",
    "| `remote_ratio` | Percentage of remote work (0/50/100) |\n",
    "| `company_location` | Country where company is located |\n",
    "| `company_size` | Size of company (S/M/L) |\n",
    "\n",
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Importing required libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9d46b2-d81c-4fee-a1db-8f88472673b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1a21aa-7e9c-4751-a745-3041fb3efe0b",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Data loading</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f877f5e-233a-4cc4-a9a7-91f9d1587cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (136757, 11)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>132600</td>\n",
       "      <td>USD</td>\n",
       "      <td>132600</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>102000</td>\n",
       "      <td>USD</td>\n",
       "      <td>102000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Product Manager</td>\n",
       "      <td>260520</td>\n",
       "      <td>USD</td>\n",
       "      <td>260520</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Product Manager</td>\n",
       "      <td>140280</td>\n",
       "      <td>USD</td>\n",
       "      <td>140280</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>215000</td>\n",
       "      <td>USD</td>\n",
       "      <td>215000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year experience_level employment_type                  job_title  \\\n",
       "0       2025               MI              FT             Data Scientist   \n",
       "1       2025               MI              FT             Data Scientist   \n",
       "2       2025               SE              FT       Data Product Manager   \n",
       "3       2025               SE              FT       Data Product Manager   \n",
       "4       2025               SE              FT  Machine Learning Engineer   \n",
       "\n",
       "   salary salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0  132600             USD         132600                 US           100   \n",
       "1  102000             USD         102000                 US           100   \n",
       "2  260520             USD         260520                 US             0   \n",
       "3  140280             USD         140280                 US             0   \n",
       "4  215000             USD         215000                 US             0   \n",
       "\n",
       "  company_location company_size  \n",
       "0               US            M  \n",
       "1               US            M  \n",
       "2               US            M  \n",
       "3               US            M  \n",
       "4               US            M  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('salaries.csv')\n",
    "\n",
    "print('Dataset shape:', df.shape)\n",
    "print('\\nFirst 5 rows:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ac6561-64fa-4e27-9502-c4db2f59b4fb",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Duplicate removal</div>\n",
    "\n",
    "Checking for and removing duplicate records to ensure data quality and avoid bias in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3b6ed7-1cd2-4cbd-b40d-e881dcfecc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate analysis:\n",
      "Total records: 136757\n",
      "Duplicates found: 70694\n",
      "Duplicate percentage: 51.7%\n"
     ]
    }
   ],
   "source": [
    "# Analyze duplicates\n",
    "print('Duplicate analysis:')\n",
    "print(f'Total records: {len(df)}')\n",
    "print(f'Duplicates found: {df.duplicated().sum()}')\n",
    "print(f'Duplicate percentage: {df.duplicated().sum()/len(df)*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aef100d-3cf7-4b0c-9276-078e615fd009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "888e50dd-ee0d-4045-8706-aa2814c1c41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing duplicates:\n",
      "Records remaining: 66063\n",
      "Duplicates remaining: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'After removing duplicates:')\n",
    "print(f'Records remaining: {len(df)}')\n",
    "print(f'Duplicates remaining: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d739def0-597b-427e-8784-927bf2fe8189",
   "metadata": {},
   "source": [
    "**Key findings:**\n",
    "\n",
    "Found 70,694 complete duplicate records (51.7% of dataset) where all sells in rows are identical. These are exact copies, not just similar salaries. All duplicate records have been removed, reducing dataset from 136,758 to approximately 66,000 unique records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c0a8d-a2dc-4eb6-a485-3457c8534d0a",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Removing redundant columns</div>\n",
    "\n",
    "Since we have salary_in_usd column which provides standardized salary values converted to USD, the original salary and salary_currency columns in various currencies are not informative for our analysis and can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e84ef965-fb53-40a9-95bd-5773bdcefc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after removing salary column: (66063, 9)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['salary', 'salary_currency'], axis=1)\n",
    "print(f'Dataset shape after removing salary column: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9141576-85c7-42e9-b673-d0fed9eb4d00",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Data types verification</div>\n",
    "\n",
    "Before diving into the analysis, it's essential to ensure that all columns have the correct data types. This step helps prevent errors in calculations and visualizations and guarantees the accuracy of statistical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e678b85c-d682-448c-97d0-bf98c775e930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 66063 entries, 0 to 136756\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   work_year           66063 non-null  int64 \n",
      " 1   experience_level    66063 non-null  object\n",
      " 2   employment_type     66063 non-null  object\n",
      " 3   job_title           66063 non-null  object\n",
      " 4   salary_in_usd       66063 non-null  int64 \n",
      " 5   employee_residence  66063 non-null  object\n",
      " 6   remote_ratio        66063 non-null  int64 \n",
      " 7   company_location    66063 non-null  object\n",
      " 8   company_size        66063 non-null  object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bef48-2246-4f44-affb-1a18fa7e529b",
   "metadata": {},
   "source": [
    "**Key findings:**\n",
    "\n",
    "The dataset columns have correct data types, ensuring reliable analysis. All columns have complete data with no missing values (66,063 non-null entries for each column), which simplifies our cleaning process significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174dc48b-aecd-4181-87ac-50ef11c9d7a7",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Descriptive statistics</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b40a8bc-2e63-42c4-bbf8-fafe407ba0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>work_year</th>\n",
       "      <td>66063.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.374294</td>\n",
       "      <td>0.730968</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>2025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience_level</th>\n",
       "      <td>66063</td>\n",
       "      <td>4</td>\n",
       "      <td>SE</td>\n",
       "      <td>34743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_type</th>\n",
       "      <td>66063</td>\n",
       "      <td>4</td>\n",
       "      <td>FT</td>\n",
       "      <td>65382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_title</th>\n",
       "      <td>66063</td>\n",
       "      <td>398</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>6779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary_in_usd</th>\n",
       "      <td>66063.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151148.848084</td>\n",
       "      <td>77438.922472</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>138900.0</td>\n",
       "      <td>190067.5</td>\n",
       "      <td>800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employee_residence</th>\n",
       "      <td>66063</td>\n",
       "      <td>102</td>\n",
       "      <td>US</td>\n",
       "      <td>55377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remote_ratio</th>\n",
       "      <td>66063.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.672661</td>\n",
       "      <td>42.970711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_location</th>\n",
       "      <td>66063</td>\n",
       "      <td>95</td>\n",
       "      <td>US</td>\n",
       "      <td>55439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company_size</th>\n",
       "      <td>66063</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>64319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count unique             top   freq           mean  \\\n",
       "work_year           66063.0    NaN             NaN    NaN    2024.374294   \n",
       "experience_level      66063      4              SE  34743            NaN   \n",
       "employment_type       66063      4              FT  65382            NaN   \n",
       "job_title             66063    398  Data Scientist   6779            NaN   \n",
       "salary_in_usd       66063.0    NaN             NaN    NaN  151148.848084   \n",
       "employee_residence    66063    102              US  55377            NaN   \n",
       "remote_ratio        66063.0    NaN             NaN    NaN      24.672661   \n",
       "company_location      66063     95              US  55439            NaN   \n",
       "company_size          66063      3               M  64319            NaN   \n",
       "\n",
       "                             std      min      25%       50%       75%  \\\n",
       "work_year               0.730968   2020.0   2024.0    2024.0    2025.0   \n",
       "experience_level             NaN      NaN      NaN       NaN       NaN   \n",
       "employment_type              NaN      NaN      NaN       NaN       NaN   \n",
       "job_title                    NaN      NaN      NaN       NaN       NaN   \n",
       "salary_in_usd       77438.922472  15000.0  96000.0  138900.0  190067.5   \n",
       "employee_residence           NaN      NaN      NaN       NaN       NaN   \n",
       "remote_ratio           42.970711      0.0      0.0       0.0       0.0   \n",
       "company_location             NaN      NaN      NaN       NaN       NaN   \n",
       "company_size                 NaN      NaN      NaN       NaN       NaN   \n",
       "\n",
       "                         max  \n",
       "work_year             2025.0  \n",
       "experience_level         NaN  \n",
       "employment_type          NaN  \n",
       "job_title                NaN  \n",
       "salary_in_usd       800000.0  \n",
       "employee_residence       NaN  \n",
       "remote_ratio           100.0  \n",
       "company_location         NaN  \n",
       "company_size             NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e9da14-5772-46bd-9523-76091320331c",
   "metadata": {},
   "source": [
    "**Key findings:**\n",
    "\n",
    "The descriptive statistics align with the dataset description on Kaggle. All values appear normal and realistic for Data Science/AI/ML roles, with salary ranges, experience levels, and employment types matching expected patterns.\n",
    "\n",
    "However, salary distribution raises concerns: maximum value of 800K USD compared to 75th percentile of 190K USD - nearly 4x difference. This indicates potential extreme outliers that require additional analysis and data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d91ea6c-783f-4f9f-b934-0195e74652f6",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Extreme values analysis</div>\n",
    "\n",
    "To identify potential salary outliers, I examine values above the 99,7th percentile. This threshold is commonly used in statistical analysis as it captures the top 1% of extreme values while maintaining a reasonable sample size for pattern analysis. Values above this threshold may represent either legitimate high-compensation roles or potential data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9238d26-577c-4284-b898-765d6e6b0c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "99th percentile salary threshold: $392,647\n",
      "\n",
      "Number of extreme cases: 661 (1.00%)\n"
     ]
    }
   ],
   "source": [
    "percentile_99 = df['salary_in_usd'].quantile(0.99)\n",
    "print(f'\\n99th percentile salary threshold: ${percentile_99:,.0f}')\n",
    "extreme_salaries = df[df['salary_in_usd'] > percentile_99]\n",
    "print(f'\\nNumber of extreme cases: {len(extreme_salaries)} ({len(extreme_salaries) / len(df) * 100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d64f9c6-fea9-49e9-8010-cc0be524e541",
   "metadata": {},
   "source": [
    "\n",
    "I display the top 10 salaries above the 99th percentile to examine which roles, experience levels, and company sizes are associated with unusually high compensation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6919f2a3-28ab-4591-ab81-4ae4b29bc905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>company_size</th>\n",
       "      <th>work_year</th>\n",
       "      <th>company_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123027</th>\n",
       "      <td>AI Architect</td>\n",
       "      <td>MI</td>\n",
       "      <td>800000</td>\n",
       "      <td>M</td>\n",
       "      <td>2024</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39563</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>SE</td>\n",
       "      <td>800000</td>\n",
       "      <td>M</td>\n",
       "      <td>2025</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16196</th>\n",
       "      <td>Architect</td>\n",
       "      <td>SE</td>\n",
       "      <td>800000</td>\n",
       "      <td>M</td>\n",
       "      <td>2025</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56674</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>EN</td>\n",
       "      <td>793136</td>\n",
       "      <td>M</td>\n",
       "      <td>2025</td>\n",
       "      <td>AT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123870</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>EN</td>\n",
       "      <td>774000</td>\n",
       "      <td>M</td>\n",
       "      <td>2024</td>\n",
       "      <td>MX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39889</th>\n",
       "      <td>Research Engineer</td>\n",
       "      <td>MI</td>\n",
       "      <td>750000</td>\n",
       "      <td>M</td>\n",
       "      <td>2025</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37829</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>SE</td>\n",
       "      <td>750000</td>\n",
       "      <td>M</td>\n",
       "      <td>2025</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5247</th>\n",
       "      <td>Machine Learning Scientist</td>\n",
       "      <td>SE</td>\n",
       "      <td>750000</td>\n",
       "      <td>M</td>\n",
       "      <td>2025</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127613</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>MI</td>\n",
       "      <td>750000</td>\n",
       "      <td>M</td>\n",
       "      <td>2023</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125256</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>SE</td>\n",
       "      <td>750000</td>\n",
       "      <td>M</td>\n",
       "      <td>2024</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         job_title experience_level  salary_in_usd  \\\n",
       "123027                AI Architect               MI         800000   \n",
       "39563            Software Engineer               SE         800000   \n",
       "16196                    Architect               SE         800000   \n",
       "56674                Data Engineer               EN         793136   \n",
       "123870                Data Analyst               EN         774000   \n",
       "39889            Research Engineer               MI         750000   \n",
       "37829            Software Engineer               SE         750000   \n",
       "5247    Machine Learning Scientist               SE         750000   \n",
       "127613               Data Engineer               MI         750000   \n",
       "125256                Data Analyst               SE         750000   \n",
       "\n",
       "       company_size  work_year company_location  \n",
       "123027            M       2024               CA  \n",
       "39563             M       2025               US  \n",
       "16196             M       2025               US  \n",
       "56674             M       2025               AT  \n",
       "123870            M       2024               MX  \n",
       "39889             M       2025               US  \n",
       "37829             M       2025               US  \n",
       "5247              M       2025               US  \n",
       "127613            M       2023               US  \n",
       "125256            M       2024               US  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extreme_cases = (\n",
    "    extreme_salaries[['job_title', 'experience_level', 'salary_in_usd', 'company_size', 'work_year', 'company_location']]\n",
    "    .sort_values(by='salary_in_usd', ascending=False)\n",
    ")\n",
    "extreme_cases.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a03309-ee6c-45b1-9a7c-80b4a53d6e46",
   "metadata": {},
   "source": [
    "**Key findings:**\n",
    "\n",
    "Analysis of salaries above 99th percentile (392,647 USD) reveals concerning patterns that suggest data quality issues:\n",
    "\n",
    "- Too many \"round\" salary figures (800K USD, 750K USD)\n",
    "- Entry-level positions with 793K USD salaries (unrealistic)  \n",
    "- Disproportionate concentration in medium-sized companies (99% of extreme salaries)\n",
    "\n",
    "These represent only 1% of the dataset. As the next step, I will address these extreme values to ensure data quality for reliable analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8722f037-6a8f-410a-9296-ea4bd0d4c5b2",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Handling extreme outliers</div>\n",
    "\n",
    "For proper handling of extreme salary values above the 99th percentile, I apply the following approach:\n",
    "\n",
    "1. Identify the 99th percentile of salaries, marking the top 1% of values as potential outliers\n",
    "2. Exclude these extreme values from the main dataset, creating a clean sample\n",
    "3. Calculate maximum salaries by groups using features: job title, experience level, work year, company size, and country location based on the clean sample\n",
    "4. In the original dataset, replace extreme values (above 99th percentile) with calculated group maximums from the clean sample\n",
    "5. This approach preserves realistic upper salary boundaries while removing unrealistic outliers and maintaining adequate data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d3507ec-6c90-48a2-b267-f7717c1a8e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fills target_col values with group maximum from group_cols.\n",
    "def fill_by_group_max(df, target_col, group_cols):\n",
    "    group_max = df.groupby(group_cols)[target_col].transform('max')\n",
    "    return df[target_col].mask(df[target_col] > group_max, group_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4481aa4-d9d8-43d8-9a69-cde950af7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 99th percentile and create clean dataset\n",
    "percentile_99 = df['salary_in_usd'].quantile(0.99)\n",
    "clean_df = df[df['salary_in_usd'] <= percentile_99].copy()\n",
    "\n",
    "# Define grouping columns\n",
    "group_cols = ['job_title', 'experience_level', 'work_year', 'company_size', 'company_location']\n",
    "\n",
    "# Calculate group maximums from clean data\n",
    "group_max = clean_df.groupby(group_cols)['salary_in_usd'].max().reset_index()\n",
    "\n",
    "# Merge group maximums with original dataset\n",
    "df = df.merge(group_max.rename(columns={'salary_in_usd': 'group_max_salary'}), on=group_cols, how='left')\n",
    "\n",
    "# Replace extreme values with group maximums\n",
    "df['salary_in_usd'] = df.apply(\n",
    "    lambda row: row['group_max_salary'] if row['salary_in_usd'] > percentile_99 else row['salary_in_usd'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Remove temporary column\n",
    "df.drop(columns=['group_max_salary'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44d5743f-df73-4f3d-a268-c2711374275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unresolved values in salary_in_usd: 7\n"
     ]
    }
   ],
   "source": [
    "# Check if any unresolved values remain in the salary column\n",
    "print(f'Unresolved values in salary_in_usd: {df['salary_in_usd'].isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6208ba5c-f4d9-40d2-9cb5-03ca849e29b7",
   "metadata": {},
   "source": [
    "As these 7 rows represent a negligible fraction of the dataset, and cannot be logically imputed, we will safely drop them without affecting the overall analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19fce546-b2b6-4f93-b204-304d84425dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['salary_in_usd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4025ea05-5712-456c-a845-30dbdca7f47a",
   "metadata": {},
   "source": [
    "**Key findings:**\n",
    "\n",
    "Successfully processed extreme salary outliers using group-based replacement. As these 7 rows represent a negligible fraction of the dataset, and cannot be logically imputed, we safely dropped them without affecting the overall analysis. The maximum salary is now capped at the 99th percentile, ensuring more realistic salary distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa77bdf4-379d-4570-a278-ce299db9fdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 66056 entries, 0 to 66062\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   work_year           66056 non-null  int64  \n",
      " 1   experience_level    66056 non-null  object \n",
      " 2   employment_type     66056 non-null  object \n",
      " 3   job_title           66056 non-null  object \n",
      " 4   salary_in_usd       66056 non-null  float64\n",
      " 5   employee_residence  66056 non-null  object \n",
      " 6   remote_ratio        66056 non-null  int64  \n",
      " 7   company_location    66056 non-null  object \n",
      " 8   company_size        66056 non-null  object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a8955-c9e3-4f86-9653-f4d174b0947b",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Saving cleaned dataset</div>\n",
    "\n",
    "Saving the cleaned and prepared dataset for further analysis in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa7c176c-313d-4c85-b972-a9fa87c33cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('cleaned_salaries.csv', index=False)\n",
    "print('Cleaned dataset saved successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfbbc95-92d5-49b2-af8a-def838953f7a",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Data cleaning summary</div>\n",
    "\n",
    "Through comprehensive data cleaning and preparation, I have successfully completed the following key steps:\n",
    "\n",
    "**Work completed:**\n",
    "- Loaded dataset containing 136,758 salary records with 11 variables  \n",
    "- Removed 70,694 duplicate records (51.7% of original data)  \n",
    "- Verified data types and confirmed their correctness  \n",
    "- Removed redundant columns with original salary and currency information, keeping only the standardized salary_in_usd variable\n",
    "- Identified and processed extreme salary outliers above the 99th percentile  \n",
    "- Applied group-based outlier correction; removed 7 unresolved extreme cases due to lack of matching groups  \n",
    "\n",
    "**Results achieved:**\n",
    "- Clean dataset with 66,056 unique records ready for analysis  \n",
    "- Realistic salary distribution with maximum capped at the 99th percentile  \n",
    "- All critical data quality issues resolved while preserving structure and analytical value  \n",
    "\n",
    "The dataset is now ready for comprehensive salary analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
