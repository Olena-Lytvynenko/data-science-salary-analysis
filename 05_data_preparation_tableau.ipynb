{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676ca558-c40c-4fd6-adb3-2f50bf1de8b5",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 16px;\">\n",
    "   \n",
    "# Data Science Salary - Tableau Data Preparation </div>\n",
    "\n",
    "Previously, data transformations were performed directly during the analysis process — fragmentarily, as new hypotheses and insights emerged. Now I am moving data preparation into a separate specialized notebook, focused exclusively on creating final datasets for the Tableau dashboard. This allows for a systematic and sequential approach to transformations: adding necessary calculated fields, conducting targeted transformations, and preparing data with consideration for specific interactive visualization requirements.\n",
    "\n",
    "The goal is to create two optimized CSV files, each tailored to specific analytical tasks of the dashboard and ensuring maximum Tableau performance. This approach guarantees reproducibility of the entire data preparation pipeline, maintains clean project architecture, and ensures stable visualization performance for effective presentation of results to the business audience.\n",
    "\n",
    "**Target outputs**: 2 clean CSV files ready for Tableau import\n",
    "\n",
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 16px;\">\n",
    "   \n",
    "## Dataset Preparation Strategy</div>\n",
    "\n",
    "I will create two specialized datasets for our Tableau dashboard:\n",
    "\n",
    "| **Dataset** | **Purpose** | **Key Features** |\n",
    "|-------------|-------------|-----------------| \n",
    "| `tableau_main_dataset.csv` | Core analysis with economic indicators | Salary data + GDP, population, economic metrics + AI classification |\n",
    "| `tableau_wikipedia_trends.csv` | AI/ML search trends over time | Wikipedia page views aggregated by year with 2025 extrapolation |\n",
    "\n",
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Importing required libraries</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf0e662-e763-4bb5-ac97-08a7b263b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e642c7e-58a1-44dd-8a9d-1381c27521fc",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Dataset 1: Data loading</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55a9077-b06f-4a64-b03f-777cc8c673cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shapes:\n",
      "\n",
      "Salary data: (66056, 9)\n",
      "World Bank data: (564, 7)\n"
     ]
    }
   ],
   "source": [
    "# Load all three datasets\n",
    "salary_df = pd.read_csv('cleaned_salaries.csv')\n",
    "worldbank_df = pd.read_csv('cleaned_worldbank.csv') \n",
    "\n",
    "print('\\nDataset shapes:\\n')\n",
    "print(f'Salary data: {salary_df.shape}')\n",
    "print(f'World Bank data: {worldbank_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44723f8-e824-45bb-85bd-43f366fecc80",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Dataset 1: Data integration with economic indicators</div>\n",
    "\n",
    "Integrating salary data with World Bank data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d595e6be-28f7-4112-9b9c-6c1f420c01d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Integrated dataset shape: (66056, 14)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "      <th>country_name</th>\n",
       "      <th>value_population</th>\n",
       "      <th>value_gdp_per_capita</th>\n",
       "      <th>value_education</th>\n",
       "      <th>value_internet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>132600.0</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>United States</td>\n",
       "      <td>341454306.1</td>\n",
       "      <td>92481.07</td>\n",
       "      <td>39.16</td>\n",
       "      <td>94.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>102000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>United States</td>\n",
       "      <td>341454306.1</td>\n",
       "      <td>92481.07</td>\n",
       "      <td>39.16</td>\n",
       "      <td>94.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Product Manager</td>\n",
       "      <td>260520.0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>United States</td>\n",
       "      <td>341454306.1</td>\n",
       "      <td>92481.07</td>\n",
       "      <td>39.16</td>\n",
       "      <td>94.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Product Manager</td>\n",
       "      <td>140280.0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>United States</td>\n",
       "      <td>341454306.1</td>\n",
       "      <td>92481.07</td>\n",
       "      <td>39.16</td>\n",
       "      <td>94.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>215000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "      <td>United States</td>\n",
       "      <td>341454306.1</td>\n",
       "      <td>92481.07</td>\n",
       "      <td>39.16</td>\n",
       "      <td>94.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year experience_level employment_type                  job_title  \\\n",
       "0       2025               MI              FT             Data Scientist   \n",
       "1       2025               MI              FT             Data Scientist   \n",
       "2       2025               SE              FT       Data Product Manager   \n",
       "3       2025               SE              FT       Data Product Manager   \n",
       "4       2025               SE              FT  Machine Learning Engineer   \n",
       "\n",
       "   salary_in_usd employee_residence  remote_ratio company_location  \\\n",
       "0       132600.0                 US           100               US   \n",
       "1       102000.0                 US           100               US   \n",
       "2       260520.0                 US             0               US   \n",
       "3       140280.0                 US             0               US   \n",
       "4       215000.0                 US             0               US   \n",
       "\n",
       "  company_size   country_name  value_population  value_gdp_per_capita  \\\n",
       "0            M  United States       341454306.1              92481.07   \n",
       "1            M  United States       341454306.1              92481.07   \n",
       "2            M  United States       341454306.1              92481.07   \n",
       "3            M  United States       341454306.1              92481.07   \n",
       "4            M  United States       341454306.1              92481.07   \n",
       "\n",
       "   value_education  value_internet  \n",
       "0            39.16           94.22  \n",
       "1            39.16           94.22  \n",
       "2            39.16           94.22  \n",
       "3            39.16           94.22  \n",
       "4            39.16           94.22  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge salary data with World Bank indicators\n",
    "df = salary_df.merge(\n",
    "    worldbank_df, \n",
    "    left_on=['company_location', 'work_year'], \n",
    "    right_on=['country_code', 'year'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Remove duplicate columns\n",
    "df = df.drop(['country_code', 'year'], axis=1)\n",
    "\n",
    "print(f'\\nIntegrated dataset shape: {df.shape}\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6dd16a-d508-4a95-9a90-0e3120b27c5a",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "    \n",
    "### Dataset 1: Converting categorical codes to descriptive labels</div>\n",
    "\n",
    "To ensure clear and professional Tableau visualizations, I replace abbreviated categorical codes with their full descriptive names directly in the dataset. This eliminates the need for repetitive mapping operations in Tableau and provides immediate data readability for dashboard creation.\n",
    "\n",
    "This preprocessing approach creates self-documenting data that improves both Tableau workflow efficiency and dashboard presentation quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08025e38-bff6-47a1-a4a4-9f29aff60e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical columns updated with full descriptive names!\n",
      "\n",
      "Dataset shape: (66056, 14)\n"
     ]
    }
   ],
   "source": [
    "# Replace abbreviated codes with full descriptive names\n",
    "df['company_size'] = df['company_size'].map({\n",
    "    'S': 'Small', 'M': 'Medium', 'L': 'Large'\n",
    "})\n",
    "\n",
    "df['experience_level'] = df['experience_level'].map({\n",
    "    'EN': 'Entry', 'MI': 'Mid', 'SE': 'Senior', 'EX': 'Executive'\n",
    "})\n",
    "\n",
    "df['employment_type'] = df['employment_type'].map({\n",
    "    'FT': 'Full-time', 'PT': 'Part-time', 'CT': 'Contract', 'FL': 'Freelance'\n",
    "})\n",
    "\n",
    "df['remote_ratio'] = df['remote_ratio'].map({\n",
    "    0: 'On-site', 50: 'Hybrid', 100: 'Fully Remote'\n",
    "})\n",
    "\n",
    "print('\\nCategorical columns updated with full descriptive names!')\n",
    "print(f'\\nDataset shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e258c-f985-4d79-90a8-573a25e952bd",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Dataset 1: AI role classification</div>\n",
    "\n",
    "Adding AI role classification column to enable filtering between traditional Data Science roles and AI-specific positions for ChatGPT impact analysis and dashboard visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a44e28-b1f4-4649-ba6f-cc45fdb6a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifies job titles as AI-related based on keywords\n",
    "def is_ai_profession(job_title):\n",
    "    ai_keywords = ['ai ', 'machine learning', 'deep learning', 'computer vision', 'nlp', 'llm', 'genai']\n",
    "    if any(keyword in job_title.lower() for keyword in ai_keywords):\n",
    "        return 'AI Role'\n",
    "    else:\n",
    "        return 'Traditional DS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0cf689-8766-498e-828a-9efd8a9810da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI roles identified: 5955 (9.0%)\n"
     ]
    }
   ],
   "source": [
    "# Add AI role classification\n",
    "df['role_category'] = df['job_title'].apply(is_ai_profession)\n",
    "\n",
    "print(f'AI roles identified: {(df[\"role_category\"] == \"AI Role\").sum()} ({(df[\"role_category\"] == \"AI Role\").mean()*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33182620-5114-41e5-9424-1c0b881ee267",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Dataset 1: Saving main analytical data with economic indicators</div>\n",
    "\n",
    "I have assembled the main dataset combining salary data, World Bank economic indicators, and AI role classification. Now I am saving this file — it will become the key foundation for geographic analysis, company size comparisons, and creating visualizations in Tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f2fb5d7-4205-4f93-b4d4-510a91e1263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main dataset saved: (66056, 15)\n"
     ]
    }
   ],
   "source": [
    "# Save main dataset for Tableau\n",
    "df.to_csv('tableau_main_dataset.csv', index=True)\n",
    "\n",
    "print(f'\\nMain dataset saved: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a33f8bf-3f0c-4b65-becf-b84ce873a07a",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Dataset 2: Wikipedia AI trends data</div>\n",
    "\n",
    "Preparing Wikipedia search trends to show correlation between AI interest and salary growth in our dual-axis Tableau visualizations. I will aggregate daily data into yearly trends and create combined AI category for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "211d3d25-5050-4119-8177-0f1d20270ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wikipedia data loaded: (10035, 5)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>keyword</th>\n",
       "      <th>views</th>\n",
       "      <th>category</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>0</td>\n",
       "      <td>AI</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>ai</td>\n",
       "      <td>6572</td>\n",
       "      <td>AI</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>ml</td>\n",
       "      <td>2867</td>\n",
       "      <td>AI</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>dl</td>\n",
       "      <td>1672</td>\n",
       "      <td>AI</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>python</td>\n",
       "      <td>4685</td>\n",
       "      <td>Programming</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  keyword  views     category  period\n",
       "0  2020-01-01  chatgpt      0           AI  before\n",
       "1  2020-01-01       ai   6572           AI  before\n",
       "2  2020-01-01       ml   2867           AI  before\n",
       "3  2020-01-01       dl   1672           AI  before\n",
       "4  2020-01-01   python   4685  Programming  before"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Wikipedia trends data\n",
    "wikipedia_df = pd.read_csv('wikipedia_data_complete.csv')\n",
    "\n",
    "print(f'\\nWikipedia data loaded: {wikipedia_df.shape}\\n')\n",
    "wikipedia_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e4fdd-0d7a-49c6-8b5b-6699a8e63ae5",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Dataset 2: Extrapolating incomplete 2025 Wikipedia data</div>\n",
    "\n",
    "Since our Wikipedia dataset contains only partial 2025 data, I extrapolate annual figures using daily averages to maintain statistical comparability with complete years for accurate before/after ChatGPT analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7379f0f3-9a59-486b-b9dc-27454011dd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025 data: from 2025-01-01 00:00:00 to 2025-06-29 00:00:00\n",
      "Available days: 180\n",
      "\n",
      "Extrapolated 2025 annual views:\n",
      "keyword\n",
      "ai          8678925.0\n",
      "chatgpt    44811520.0\n",
      "dl           824304.0\n",
      "ml          1944116.0\n",
      "python      4110748.0\n",
      "Name: views, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert date column and check 2025 completeness\n",
    "wikipedia_df['date'] = pd.to_datetime(wikipedia_df['date'])\n",
    "wiki_2025 = wikipedia_df[wikipedia_df['date'].dt.year == 2025]\n",
    "\n",
    "print(f'2025 data: from {wiki_2025[\"date\"].min()} to {wiki_2025[\"date\"].max()}')\n",
    "days_available = wiki_2025['date'].nunique()\n",
    "print(f'Available days: {days_available}')\n",
    "\n",
    "# Extrapolate to full year\n",
    "daily_avg = wiki_2025.groupby('keyword')['views'].sum() / days_available\n",
    "wiki_2025_adjusted = daily_avg * 365\n",
    "\n",
    "print(f'\\nExtrapolated 2025 annual views:')\n",
    "print(wiki_2025_adjusted.round(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0067e64-3531-4352-9f49-de1ffd6f58fb",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Dataset 2: Creating complete annual dataset</div>\n",
    "\n",
    "Building comprehensive yearly data combining complete years (2020-2024) with extrapolated 2025 figures for accurate trend analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5b0472d-343f-4d4f-95b2-7c14c4a86858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of final data:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>keyword</th>\n",
       "      <th>annual_views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>ai</td>\n",
       "      <td>3429230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>chatgpt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>dl</td>\n",
       "      <td>972118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>ml</td>\n",
       "      <td>1799644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>python</td>\n",
       "      <td>3434807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  keyword  annual_views\n",
       "0  2020       ai       3429230\n",
       "1  2020  chatgpt             0\n",
       "2  2020       dl        972118\n",
       "3  2020       ml       1799644\n",
       "4  2020   python       3434807"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude partial 2025 data and aggregate complete years\n",
    "wiki_without_2025 = wikipedia_df[wikipedia_df['date'].dt.year != 2025]\n",
    "wiki_tableau = wiki_without_2025.groupby([wiki_without_2025['date'].dt.year, 'keyword'])['views'].sum().reset_index()\n",
    "wiki_tableau.columns = ['year', 'keyword', 'annual_views']\n",
    "\n",
    "# Add extrapolated 2025 data\n",
    "for term in ['ai', 'ml', 'dl', 'python', 'chatgpt']:\n",
    "    if term in wiki_2025_adjusted.index:\n",
    "        new_row = pd.DataFrame({\n",
    "            'year': [2025],\n",
    "            'keyword': [term], \n",
    "            'annual_views': [int(wiki_2025_adjusted[term])]\n",
    "        })\n",
    "        wiki_tableau = pd.concat([wiki_tableau, new_row], ignore_index=True)\n",
    "\n",
    "print('\\nSample of final data:\\n')\n",
    "wiki_tableau.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaff757-44bb-422b-b7e4-a7d728384a3c",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Dataset 2: Saving Wikipedia AI trends data</div>\n",
    "\n",
    "I have processed and aggregated Wikipedia page view data for AI-related keywords, including extrapolation of incomplete 2025 data to ensure statistical accuracy. This dataset will enable dual-axis visualizations showing correlation between AI search interest and salary trends over time in Tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeba3346-b300-40f0-bd66-311a6974b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем ID колонку явно\n",
    "df['ID'] = range(len(df))\n",
    "\n",
    "# Сохраняем с ID в начале\n",
    "df = df[['ID'] + [col for col in df.columns if col != 'ID']]\n",
    "df.to_csv('tableau_main_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1155149d-b3b4-4b02-9e67-80b3f5e44584",
   "metadata": {},
   "source": [
    "<div style=\"color: #095AAD; font-weight: bold; font-size: 15px;\">\n",
    "\n",
    "### Data preparation summary</div>\n",
    "\n",
    "Successfully prepared two specialized datasets for our comprehensive Tableau dashboard analyzing Data Science salary trends and AI revolution impact.\n",
    "\n",
    "**Work completed:**\n",
    "- Transformed categorical codes into descriptive labels for improved dashboard readability\n",
    "- Added AI role classification to enable filtering between traditional Data Science and AI-specific positions\n",
    "- Created complete annual Wikipedia trends dataset with extrapolated 2025 data for accurate time-series analysis\n",
    "- Ensured proper data relationships between salary and search trend datasets via year linkage\n",
    "\n",
    "**Results achieved:**\n",
    "- **tableau_main_dataset.csv**: Comprehensive dataset with salary data, economic indicators, and AI classification ready for geographic analysis and company comparisons\n",
    "- **tableau_wikipedia_trends.csv**: Annual page view trends for AI keywords enabling correlation analysis with salary growth\n",
    "\n",
    "Both datasets are optimized for Tableau performance and ready for professional business intelligence analysis. The ChatGPT impact analysis will be performed directly in Tableau using calculated fields from the main dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
